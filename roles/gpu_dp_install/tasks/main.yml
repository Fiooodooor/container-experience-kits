##
##   Copyright (c) 2020-2023 Intel Corporation.
##
##   Licensed under the Apache License, Version 2.0 (the "License");
##   you may not use this file except in compliance with the License.
##   You may obtain a copy of the License at
##
##       http://www.apache.org/licenses/LICENSE-2.0
##
##   Unless required by applicable law or agreed to in writing, software
##   distributed under the License is distributed on an "AS IS" BASIS,
##   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
##   See the License for the specific language governing permissions and
##   limitations under the License.
##
---
- name: install dependencies
  include_role:
    name: install_dependencies

# docker is used as container runtime:
- name: prepare image for Intel GPU Device Plugin
  block:
    - name: build Intel GPU Device Plugin images
      make:
        target: "{{ item }}"
        chdir: "{{ intel_dp_dir }}"
      loop:
        - intel-gpu-plugin
        - intel-gpu-initcontainer

    - name: tag Intel GPU Device Plugin images
      command: docker tag intel/{{ item }}:{{ intel_dp_version }} {{ registry_local_address }}/{{ item }}:{{ intel_dp_version }}
      changed_when: true
      loop:
        - intel-gpu-plugin
        - intel-gpu-initcontainer

    - name: push Intel GPU Device Plugin image to local registry
      command: docker push {{ registry_local_address }}/{{ item }}:{{ intel_dp_version }}
      changed_when: true
      loop:
        - intel-gpu-plugin
        - intel-gpu-initcontainer
  when:
    - inventory_hostname == groups['kube_node'][0]
    - gpu_dp_build_image_locally
    - container_runtime == "docker"

# containerd/cri-o is used as container runtime:
- name: prepare image for Intel GPU Device Plugin
  block:
    - name: build and tag Intel GPU Device Plugin image
      command: podman build -f build/docker/{{ item.file }} . -t {{ registry_local_address }}/{{ item.name }}:{{ intel_dp_version }}
      args:
        chdir: "{{ intel_dp_dir }}"
      changed_when: true
      with_items:
        - {file: intel-gpu-initcontainer.Dockerfile, name: intel-gpu-initcontainer}
        - {file: intel-gpu-plugin.Dockerfile, name: intel-gpu-plugin}

    - name: push Intel GPU Device Plugin image to local registry
      command: podman push {{ registry_local_address }}/{{ item.name }}:{{ intel_dp_version }}
      changed_when: true
      with_items:
        - {name: intel-gpu-initcontainer}
        - {name: intel-gpu-plugin}
  when:
    - inventory_hostname == groups['kube_node'][0]
    - gpu_dp_build_image_locally
    - '"docker" not in container_runtime'

# start deployment of GPU DP
- name: prepare and deploy GPU Device Plugin
  block:
    - name: set values
      set_fact:
        intel_gpu_dp_image: "{{ registry_local_address }}/intel-gpu-plugin:{{ intel_dp_version }}"
        intel_gpu_dp_init_image: "{{ registry_local_address }}/intel-gpu-initcontainer:{{ intel_dp_version }}"
      when: gpu_dp_build_image_locally

    - name: Set GPU oem kernel version based on OS version
      include_role:
        name: bootstrap/install_gpu_driver # noqa role-name[path] - role in bootstrap
        tasks_from: set_oem_kernel_version

    - name: populate Intel GPU Device Plugin yaml file and push to controller node
      template:
        src: "intel-gpu-plugin.yml.j2"
        dest: "{{ (intel_dp_templates_dir, 'intel-gpu-plugin.yml') | path_join }}"
        force: yes
        mode: preserve
      # vars:
      #   target_kernel_version: "{{ gpu_oem_kernel_version }}"

    - name: deploy Intel GPU Device Plugin with the Intel Device Plugin Operator
      k8s:
        state: present
        src: "{{ (intel_dp_templates_dir, 'intel-gpu-plugin.yml') | path_join }}"
  when: inventory_hostname == groups['kube_control_plane'][0]
