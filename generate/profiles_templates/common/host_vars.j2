---
# Kubernetes node configuration
# Do not change profile_name and configured_arch here !!!
# To generate vars for different profile/architecture use make command
# generated for profile and arch:
profile_name: {{ name }}
configured_arch: {{ arch }}

{% if sriov_network_dp in ['on', 'optional'] or qat in ['on', 'optional'] -%}
# Enable IOMMU (required for SR-IOV networking and QAT)
iommu_enabled: {% if (sriov_network_dp == 'on' or qat == 'on') and on_vms != 'on' %}true{% else %}false{% endif %}
{% endif %}

{%- if sriov_network_dp in ['on', 'optional'] or minio in ['on', 'optional'] %}
# dataplane interface configuration list
dataplane_interfaces: []
{%- if on_vms == 'on' %}
#  - name: enp4s0                 # PF interface name
#    bus_info: "04:00.0"             # pci bus info
#    pf_driver: iavf              # driver inside VM
#    sriov_numvfs: 0
#    default_vf_driver: "igb_uio"
#  - name: enp5s0                 # PF interface name
#    bus_info: "05:00.0"             # pci bus info
#    pf_driver: iavf              # driver inside VM
#    sriov_numvfs: 0
#    default_vf_driver: "igb_uio"
#  - name: enp6s0                 # PF interface name
#    bus_info: "06:00.0"             # pci bus info
#    pf_driver: iavf              # driver inside VM
#    sriov_numvfs: 0
#    default_vf_driver: "iavf"
#  - name: enp7s0                 # PF interface name
#    bus_info: "07:00.0"             # pci bus info
#    pf_driver: iavf              # driver inside VM
#    sriov_numvfs: 0
#    default_vf_driver: "iavf"
{%- else %}
#  - name: enp24s0f0                        # PF interface name
#    bus_info: "18:00.0"                    # pci bus info
#    pf_driver: ice                         # PF driver, "i40e", "ice"
{%- if ddp in ['on', 'optional'] %}
#    ddp_profile: "ice_comms-1.3.31.0.pkg"  # DDP package name to be loaded into the NIC
                                            # For i40e(XV710-*) allowable ddp values are: "ecpri.pkg", "esp-ah.pkg", "ppp-oe-ol2tpv2.pkgo", "mplsogreudp.pkg" and "gtp.pkgo", replace as required
                                            # For ice(E810-*) allowable ddp values are: ice_comms-1.3.[17,20,22,24,28,30,31].0.pkg  such as "ice_comms-1.3.31.0.pkg", replace as required
                                            # ddp_profile must be defined for first port of each network device. bifurcated cards will appear as unique devices.
{% endif %}
#    default_vf_driver: "iavf"              # default driver to be used with VFs if specific driver is not defined in the "sriov_vfs" section
#    sriov_numvfs: 6                        # total number of VFs to create including VFs listed in the "sriov_vfs" section.
                                            # If total number of VFs listed in the "sriov_vfs" section is greater than "sriov_numvfs" then excessive entities will be ignored.
                                            # VF's name should follow scheme: <arbitrary_vf_name>_<zero_started_index_of_vf>
                                            # If index in the VF's name is greater than "sriov_numfs - 1" such VF will be ignored.
#    sriov_vfs:                             # list of VFs to create on this PF with specific driver
#      vf_00: "vfio-pci"                    # VF driver to be attached to this VF under this PF. Options: "iavf", "vfio-pci", "igb_uio"
#      vf_05: "vfio-pci"

#  - name: enp24s0f1
#    bus_info: "18:00.1"
#    pf_driver: ice
{%- if ddp in ['on', 'optional'] %}
#    ddp_profile: "ice_comms-1.3.31.0.pkg"
{%- endif %}
#    default_vf_driver: "vfio-pci"
#    sriov_numvfs: 4
#    sriov_vfs: {}                   # no VFs with specific driver on this PF or "sriov_vfs" can be omitted for convenience
{%- endif %}

sriov_cni_enabled: {% if sriov_network_dp == 'on' %}true{% else %}false{% endif %}
{% endif %}

{%- if sriov_operator in ['on', 'optional'] %}
# Custom SriovNetworkNodePolicy manifests local path
# custom_sriov_network_policies_dir: /tmp/sriov
{%- endif %}

{%- if bond_cni in ['on', 'optional'] %}
# Bond CNI
bond_cni_enabled: {% if bond_cni == 'on' %}true{% else %}false{% endif %}
{% endif %}

{%- if dpdk in ['on', 'optional'] %}
# Install DPDK (required for SR-IOV networking)
install_dpdk: {% if dpdk == 'on' %}true{% else %}false{% endif %}
# DPDK version (will be in action if install_dpdk: true)
dpdk_version: "21.11"
# Custom DPDK patches local path
#dpdk_local_patches_dir: "/tmp/patches/dpdk"
# It might be necessary to adjust the patch strip parameter, update as required.
#dpdk_local_patches_strip: 0
{%- endif %}
{% if network_userspace in ['on', 'optional'] %}
# Userspace networking
userspace_cni_enabled: {% if network_userspace == 'on' %}true{% else %}false{% endif %}
ovs_dpdk_enabled: {% if ovs_dpdk == 'on' %}true{% else %}false{% endif %} # Should be enabled with Userspace CNI, when VPP is set to "false"; 1G hugepages required
ovs_version: "v2.16.2"
# CPU mask for OVS-DPDK PMD threads
ovs_dpdk_lcore_mask: 0x1
# Huge memory pages allocated by OVS-DPDK per NUMA node in megabytes
# example 1: "256,512" will allocate 256MB from node 0 and 512MB from node 1
# example 2: "1024" will allocate 1GB from node 0 on a single socket board, e.g. in a VM
ovs_dpdk_socket_mem: "256,0"
vpp_enabled: {% if vpp == 'on'%}true{% else %}false{% endif %} # Should be enabled with Userspace CNI, when ovs_dpdk is set to "false"; 2M hugepages required
{% endif %}
# Set to 'true' to update i40e, ice and iavf kernel modules
update_nic_drivers: {% if sriov_network_dp != 'on' and on_vms == 'on' %}false{% else %}true{% endif %}
# Set 'true' to update NIC firmware
update_nic_firmware: false # FW update will be executed on all NICs listed in "dataplane_interfaces[*].name"

{% if sriov_network_dp in ['on', 'optional'] or qat in ['on', 'optional'] or network_userspace in ['on', 'optional'] -%}
# Enables hugepages support
hugepages_enabled: {% if sriov_network_dp == 'on' or qat == 'on' or network_userspace == 'on' %}true{% else %}false{% endif %}
# Hugepage sizes available: 2M, 1G
default_hugepage_size: {% if vpp == 'on' %}2M{% else %}1G{% endif %}
# Sets how many hugepages should be created
number_of_hugepages_1G: 4
number_of_hugepages_2M: 128
{% endif %}

{%- if ddp in ['on', 'optional'] %}
# install Intel x700 & x800 series NICs DDP packages
install_ddp_packages: {% if ddp == "on" %}true{% else %}false{% endif %}
# If following error appears: "Flashing failed: Operation not permitted"
# run deployment with update_nic_firmware: true
# or
# Disable ddp installation via install_ddp_packages: false

# set 'true' to enable custom ddp package to be loaded after reboot
enable_ice_systemd_service: {% if ddp == "on" %}true{% else %}false{% endif %}
{% endif %}

{%- if qat in ['on', 'optional'] %}
# Enabling this feature will install QAT drivers + services
update_qat_drivers: {% if qat == "on" %}true{% else %}false{% endif %}

# qat interface configuration list
qat_devices: []
{%- if on_vms == 'on' %}
#  - qat_id: "0000:08:00.0"
#    qat_sriov_numvfs: 0              # Have to be set to 0 here to not create any VFs inside VM.

#  - qat_id: "0000:09:00.0"
#    qat_sriov_numvfs: 0              # Have to be set to 0 here to not create any VFs inside VM.
{%- else %}
#  - qat_id: "0000:ab:00.0"           # QAT device id one using DPDK compatible driver for VF devices to be used by vfio-pci kernel driver, replace as required
#    qat_sriov_numvfs: 12             # Number of VFs per PF to create - cannot exceed the maximum number of VFs available for the device. Set to 0 to not create any VFs.
                                      # Note: Currently when trying to create fewer virtual functions than the maximum, the maximum number always gets created
#  - qat_id: "0000:xy:00.0"
#    qat_sriov_numvfs: 10

#  - qat_id: "0000:yz:00.0"
#    qat_sriov_numvfs: 10
{%- endif %}
{% endif %}

{%- if openssl in ['on', 'optional'] %}
# Install and configure OpenSSL cryptography
openssl_install: {% if openssl == 'on' and qat == "on" %}true{% else %}false{% endif %} # This requires update_qat_drivers set to 'true' in host vars
{% endif %}

{%- if isolcpu in ["on", "optional"] %}
# CPU isolation from Linux scheduler
isolcpus_enabled: {% if isolcpu == 'on' %}true{% else %}false{% endif %}
{%- if on_vms == 'on' %}
isolcpus: "4-15"
{%- else %}
isolcpus: "4-11"
{%- endif %}
{% endif %}

{%- if native_cpu_manager in ["on", "optional"] %}
# Native CPU Manager (Kubernetes built-in)
# These settings are relevant only if in group_vars native_cpu_manager_enabled: true
# Amount of CPU cores that will be reserved for the housekeeping (2000m = 2000 millicores = 2 cores)
native_cpu_manager_system_reserved_cpus: 2000m
# Amount of CPU cores that will be reserved for Kubelet
native_cpu_manager_kube_reserved_cpus: 1000m
# Explicit list of the CPUs reserved for the host level system threads and Kubernetes related threads
#native_cpu_manager_reserved_cpus: "0,1,2"
# Note: All remaining unreserved CPU cores will be consumed by the workloads.
{% endif %}
{%- if (pstate in ['on', 'optional'] or sst in ['on', 'optional']) and arch in ['clx', 'icx', 'spr'] %}
# Enable/Disable Intel PState scaling driver
intel_pstate_enabled: {% if pstate == "on" or sst == "on" %}true{% else %}false{% endif %}
# Config options for intel_pstate: disable, passive, force, no_hwp, hwp_only, support_acpi_ppc, per_cpu_perf_limits
intel_pstate: {% if pstate == "on" or sst == "on" %}hwp_only{% else %}disable{% endif %}
# Enable/Disable Intel Turbo Boost PState attribute
turbo_boost_enabled: {% if on_vms != 'on' %}true{% else %}false{% endif %}
{% endif -%}

{% if sst in ['on', 'optional'] %}
{%- if arch in ['icx', 'spr'] %}
# Intel(R) SST-PP (perf-profile) configuration
# [true] Enable Intel(R) SST-PP (perf-profile)
# [false] Disable Intel(R) SST-PP (perf-profile)
sst_pp_configuration_enabled: {% if sst == "on" %}true{% else %}false{% endif %}
sst_pp_config_list:             # "enable" or "disable" list options per SST-PP setup requirements
    - sst_bf: "enable"          # "enable" or "disable" Intel(R) SST-BF (base-freq) to configure with SST-PP
    - sst_cp: "enable"          # "enable" or "disable" Intel(R) SST-CP (core-power) to configure with SST-PP.
    - sst_tf: "enable"          # "enable" or "disable" Intel(R) SST-TF (turbo-freq) to configure with SST-PP.
      online_cpus_range: "auto" # "auto" will config turbo-freq for all available online CPUs or else define specific CPUs such as "2,3,5" to prioritize among others.
{% endif %}
# Intel Speed Select Base-Frequency configuration.
{%- if arch == 'clx' %}
sst_bf_configuration_enabled: {% if sst == "on" %}true{% else %}false{% endif %}
# Intel Speed Select Base-Frequency configuration for Cascade Lake (CLX) Platforms.
# CLX support of SST-BF requires 'intel_pstate' to be 'enabled'
# Option clx_sst_bf_mode requires sst_bf_configuration_enabled to be set to 'true'.
# There are three configuration modes:
# [s] Set SST-BF config (set min/max to 2700/2700 and 2100/2100)
# [m] Set P1 on all cores (set min/max to 2300/2300)
# [r] Revert cores to min/Turbo (set min/max to 800/3900)
clx_sst_bf_mode: s
{%- endif %}
{%- if arch == 'icx' %}
# Intel Speed Select Base-Frequency configuration for Ice Lake (ICX) Platforms.
# [true] Enable Intel Speed Select Base Frequency (SST-BF)
# [false] Disable Intel Speed Select Base Frequency (SST-BF)
# Requires `sst_bf_configuration_enabled` variable to be 'true'
icx_sst_bf_enabled: {% if sst == "on" %}true{% else %}false{% endif %}
# Prioritze (SST-CP) power flow to high frequency cores in case of CPU power constraints.
icx_sst_bf_with_core_priority: {% if sst == "on" %}true{% else %}false{% endif %}

# SST CP config
# Variables are only examples.
# For more information, please visit:
# https://www.kernel.org/doc/html/latest/admin-guide/pm/intel-speed-select.html#enable-clos-based-prioritization
# Enabling this configuration overrides `icx_sst_bf_with_core_priority`.
sst_cp_configuration_enabled: {% if sst == "on" %}true{% else %}false{% endif %}
sst_cp_priority_type: "1" # For Proportional select "0" and for Ordered select "1", update as required
sst_cp_clos_groups: # configure up to 4 CLOS groups
  - id: 0
    frequency_weight: 0 # used only with Proportional type
    min_MHz: 0
    max_MHz: 25500
  - id: 1
    frequency_weight: 0 # used only with Proportional type
    min_MHz: 0
    max_MHz: 25500
  - id: 2
    frequency_weight: 0 # used only with Proportional type
    min_MHz: 0
    max_MHz: 25500
  - id: 3
    frequency_weight: 0 # used only with Proportional type
    min_MHz: 0
    max_MHz: 25500
sst_cp_cpu_clos: # assign required values to CLOS group after priority type setup
  - clos: 0
    cpus: 1,2,4..6,8-10
  - clos: 1
    cpus: 3,7

# Intel(R) SST-TF (feature turbo-freq) configuration for Ice Lake (ICX) Platforms.
# [true] Enable Intel Speed Select Turbo Frequency (SST-TF)
# [false] Disable Intel Speed Select Turbo Frequency (SST-TF)
sst_tf_configuration_enabled: {% if sst == "on" %}true{% else %}false{% endif %}
{%- endif %}
{% endif %}

{%- if sgx in ['on', 'optional'] and arch in ['icx', 'spr'] %}
# Intel Software Guard Extensions (SGX)
configure_sgx: {% if sgx == 'on' %}true{% else %}false{% endif %}
{% endif %}

{%- if telemetry in ['on', 'optional'] %}
# Telemetry configuration
# intel_pmu plugin collects information provided by Linux perf interface.
enable_intel_pmu_plugin: false

# CPU Threads to be monitored by Intel PMU Plugin.
# If the field is empty, all available cores will be monitored.
# Please refer to https://collectd.org/wiki/index.php/Plugin:Intel_PMU for configuration details.
intel_pmu_plugin_monitored_cores: ""

# CPU Threads to be monitored by Intel RDT Plugin.
# If the field is empty, all available cores will be monitored.
# Please refer to https://collectd.org/wiki/index.php/Plugin:IntelRDT for configuration details.
intel_rdt_plugin_monitored_cores: ""

# Additional list of plugins that will be excluded from collectd deployment.
exclude_collectd_plugins: []
{% endif %}

{%- if vm_mode in ['on'] and on_vms != 'on' %}
# VM image version for Ubuntu 20.04 - focal
vm_image_version: "20.04"
vms:
  - type: "ctrl"
    name: "vm-ctrl-1"
    cpus: "8-11,64-67"
    emu_cpus: "8,64"
    numa: 0
    cpu_total: 8
    memory: 20480
  - type: "work"
    name: "vm-work-1"
    cpus: "12-19,68-75"
    emu_cpus: "12,68"
    numa: 0
    cpu_total: 16
    memory: 61440
{%- if name in ['access', 'full_nfv', 'on_prem', 'remote_fp'] %}
    pci:
      - "18:02.2"
      - "18:02.3"
      - "18:02.4"
      - "18:02.5"
{%- if qat == "on" %}
#      - "3d:01.1"
#      - "3f:01.1"
{%- endif %}
{%- else %}
    pci: []
{%- endif %}
{% endif -%}
{%- if power_manager in ['on', 'optional'] and arch in ['icx', 'clx', 'spr'] %}
# Power Operator Shared Profile/Workload settings.
# It is possible to create node-specific Power Profile
local_shared_profile:
  enabled: false
  node_max_shared_frequency: 2000
  node_min_shared_frequency: 1500

# Shared Workload is required to make use of Shared Power Profile
shared_workload:
  enabled: false
  reserved_cpus: []  # The CPUs in reserved_cpus should match the value of the reserved system CPUs in your Kubelet config file, if none please
                     # set here a dummy core - the last one to avoid AppQos bug
  shared_workload_type: "global"  # set to node name to make use of node-specific Power Profile, 'global' means use cluster-specific custom Power Profile
{% endif %}
{%- if minio in ['on', 'optional'] %}
# MinIO storage configuration
minio_pv: []
#  - name: "mnt-data-1"                        # PV identifier will be used for PVs names followed by node name(e.g., mnt-data-1-hostname)
#    storageClassName: "local-storage"         # Storage class name to match with PVC
#    accessMode: "ReadWriteOnce"               # Access mode when mounting a volume, e.g., ReadWriteOnce/ReadOnlyMany/ReadWriteMany/ReadWriteOncePod
#    persistentVolumeReclaimPolicy: "Retain"   # Recalim policy when a volume is released once it's bound, e.g., Retain/Recycle/Delete
#    capacity: 1GiB                            # Size of the PV. support only GiB/TiB
#    mountPath: /mnt/data0                     # Mount path of a volume
#    device: /dev/nvme0n1                      # Target storage device name when creating a volume.
                                               # When group_vars: minio_deploy_test_mode == true, use a file as a loop device for storage
                                               # otherwise, an actual NVME or SSD device for storage on the device name.

#  - name: "mnt-data-2"
#    storageClassName: "local-storage"
#    accessMode: "ReadWriteOnce"
#    persistentVolumeReclaimPolicy: "Retain"
#    capacity: 1GiB
#    mountPath: /mnt/data1
#    device: /dev/nvme1n1

#  - name: "mnt-data-3"
#    storageClassName: "local-storage"
#    accessMode: "ReadWriteOnce"
#    persistentVolumeReclaimPolicy: "Retain"
#    capacity: 1GiB
#    mountPath: /mnt/data2
#    device: /dev/nvme2n1

#  - name: "mnt-data-4"
#    storageClassName: "local-storage"
#    accessMode: "ReadWriteOnce"
#    persistentVolumeReclaimPolicy: "Retain"
#    capacity: 1GiB
#    mountPath: /mnt/data3
#    device: /dev/nvme3n1
{% endif -%}
